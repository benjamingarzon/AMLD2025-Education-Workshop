{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d34927",
   "metadata": {
    "id": "b8d34927"
   },
   "source": [
    "## Deep Knowledge Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c87c5e",
   "metadata": {
    "id": "c4c87c5e"
   },
   "source": [
    "We will try out three different deep learning models for Knowledge Tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d5f31a",
   "metadata": {
    "executionInfo": {
     "elapsed": 1979,
     "status": "ok",
     "timestamp": 1739188664514,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "c9d5f31a"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import gdown\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4303fab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1418,
     "status": "ok",
     "timestamp": 1739188665935,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "d4303fab",
    "outputId": "577e6a93-f040-44ed-99a7-82dc931ec5d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'AMLD2025-Education-Workshop'...\n",
      "remote: Enumerating objects: 144, done.\u001b[K\n",
      "remote: Counting objects: 100% (144/144), done.\u001b[K\n",
      "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
      "remote: Total 144 (delta 57), reused 113 (delta 29), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (144/144), 1.67 MiB | 5.27 MiB/s, done.\n",
      "Resolving deltas: 100% (57/57), done.\n",
      "/content/AMLD2025-Education-Workshop\n"
     ]
    }
   ],
   "source": [
    "# If running on colab, clone the repo\n",
    "!git clone https://github.com/benjamingarzon/AMLD2025-Education-Workshop.git\n",
    "%cd AMLD2025-Education-Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a507e09b",
   "metadata": {
    "id": "a507e09b"
   },
   "source": [
    "# Data\n",
    "\n",
    "We will fit data from the Assistments platform (https://new.assistments.org/). These data are from the course 2009.\n",
    "\n",
    "First make sure to download the data from https://drive.google.com/uc?id=1y_1QJ1piwRlM9WXjyR2_4Yk19NubVpjM and save it in the folder **./DeepModels/datasets/ASSIST2009/**. The data preparation script assumes that the data are in a file **./DeepModels/datasets/ASSIST2009/skill_builder_data.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2163acd0",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1739188667452,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "2163acd0"
   },
   "outputs": [],
   "source": [
    "url = \"https://drive.google.com/uc?id=1y_1QJ1piwRlM9WXjyR2_4Yk19NubVpjM\"\n",
    "output = \"skill_builder_data.zip\"\n",
    "gdown.download(url, output, quiet=False)\n",
    "!unzip skill_builder_data.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f7a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"DeepModels/datasets/ASSIST2009\", exist_ok=True)\n",
    "!mv skill_builder_data.csv DeepModels/datasets/ASSIST2009/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3441bede",
   "metadata": {
    "id": "3441bede"
   },
   "source": [
    "Inspect the data:\n",
    "- *user_id* - Student ID.\n",
    "- *order_id* - Indicates the order in which the item was presented.\n",
    "- *skill_name* - Knowledge Component (KC). Groups items (exercises/questions) of a similar topic or skill.\n",
    "- *correct* - Whether the response is correct (1) or incorrect (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94240d13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1739189228696,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "94240d13",
    "outputId": "2749fe07-52be-45f9-fb9a-74caa4498378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  order_id  assignment_id  user_id  assistment_id  problem_id  \\\n",
      "0           1  33022537         277618    64525          33139       51424   \n",
      "1           2  33022709         277618    64525          33150       51435   \n",
      "2           3  35450204         220674    70363          33159       51444   \n",
      "3           4  35450295         220674    70363          33110       51395   \n",
      "4           5  35450311         220674    70363          33196       51481   \n",
      "5           6  35450555         220674    70363          33172       51457   \n",
      "6           7  35450573         220674    70363          33174       51459   \n",
      "7           8  35480603         220674    70363          33123       51408   \n",
      "8           9  33140811         220674    70677          33168       51453   \n",
      "9          10  33140919         220674    70677          33112       51397   \n",
      "\n",
      "   original  correct  attempt_count  ms_first_response  ... hint_count  \\\n",
      "0         1        1              1              32454  ...          0   \n",
      "1         1        1              1               4922  ...          0   \n",
      "2         1        0              2              25390  ...          0   \n",
      "3         1        1              1               4859  ...          0   \n",
      "4         1        0             14              19813  ...          3   \n",
      "5         1        1              1              16031  ...          0   \n",
      "6         1        1              1              15047  ...          0   \n",
      "7         1        1              1              10732  ...          0   \n",
      "8         1        1              1              23241  ...          0   \n",
      "9         1        1              1              11512  ...          0   \n",
      "\n",
      "  hint_total  overlap_time  template_id  answer_id answer_text  first_action  \\\n",
      "0          3         32454        30799        NaN          26             0   \n",
      "1          3          4922        30799        NaN          55             0   \n",
      "2          3         42000        30799        NaN          88             0   \n",
      "3          3          4859        30059        NaN          41             0   \n",
      "4          4        124564        30060        NaN          65             0   \n",
      "5          4         16031        30060        NaN          12             0   \n",
      "6          4         15047        30060        NaN           6             0   \n",
      "7          3         10732        30059        NaN          55             0   \n",
      "8          4         23241        30060        NaN          12             0   \n",
      "9          2         11512        30059        NaN          36             0   \n",
      "\n",
      "  bottom_hint  opportunity  opportunity_original  \n",
      "0         NaN            1                   1.0  \n",
      "1         NaN            2                   2.0  \n",
      "2         NaN            1                   1.0  \n",
      "3         NaN            2                   2.0  \n",
      "4         0.0            3                   3.0  \n",
      "5         NaN            4                   4.0  \n",
      "6         NaN            5                   5.0  \n",
      "7         NaN            6                   6.0  \n",
      "8         NaN            1                   1.0  \n",
      "9         NaN            2                   2.0  \n",
      "\n",
      "[10 rows x 30 columns]\n",
      "4151\n",
      "(274590, 30)\n",
      "correct\n",
      "1    181695\n",
      "0     92895\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"DeepModels/datasets/ASSIST2009\"\n",
    "data = pd.read_csv(\n",
    "    os.path.join(data_dir, \"skill_builder_data.csv\"),\n",
    "    sep=\",\"\n",
    ")\n",
    "\n",
    "print(data.head(10))\n",
    "print(data.user_id.nunique())\n",
    "print(data.shape)\n",
    "print(data.correct.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa7030",
   "metadata": {
    "id": "27aa7030"
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "Since datasets can differ in how they are formatted, they often need specific preprocessing steps for each dataset. In the **data_loaders** folder there are preprocessing scripts for different benchmark datasets. These **data_loaders** are called when you run the model (no need to call them separately). We can run *train.py* with the option *--only_preprocess* to run only the preprocessing, to avoid a long wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d098e90d",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1739189232391,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "d098e90d"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"DeepModels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c129767",
   "metadata": {
    "executionInfo": {
     "elapsed": 16282,
     "status": "ok",
     "timestamp": 1739189249465,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "6c129767"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benja\\anaconda3\\envs\\AMLDAIEd\\Lib\\site-packages\\torch\\__init__.py:1236: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:436.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "!python train.py --model_name=dkt --dataset_name=ASSIST2009 --only_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaff23eb",
   "metadata": {
    "id": "eaff23eb"
   },
   "source": [
    "Briefly, the preprocessing implements the following steps (see train.py and data_loaders/assist2009.py):\n",
    "\n",
    "- Sort responses by order_id (time) for each student.\n",
    "- Remove observations if correct is different from 1 or 0.\n",
    "- Reindex students and items (consecutive indices starting from 0).\n",
    "- Split sequences of KCs and responses so that they have uniform length (*seq_len*).\n",
    "- Split dataset in train and test (e.g., 90%/10%).\n",
    "\n",
    "The preprocessing creates the following files that are used to train the model:\n",
    "\n",
    "*u_list.pkl*: List of student ids.\n",
    "\n",
    "*u2idx.pkl*: Dict with mapping of student ids to indices.\n",
    "\n",
    "*q_list.pkl*: List of knowledge component (KC) ids.\n",
    "\n",
    "*q2idx.pkl*: Dict with mapping of KC ids to indices.\n",
    "\n",
    "*r_seqs.pkl*: List of sequences of responses. Each element is an array that corresponds to the sequence of responses of one student, ordered by timestamp (order_id).\n",
    "\n",
    "*q_seqs.pkl*: List of sequences of KCs. Each element is an array that corresponds to the sequence of KCs of one student, ordered by timestamp (order_id). It matches r_seqs.\n",
    "\n",
    "*train_indices.pkl*, *test_indices.pkl*: training/test indices\n",
    "\n",
    "Inspect these files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313dc76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1739189249508,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "5313dc76",
    "outputId": "85aa5cf7-2e07-4d40-9462-e9644363867c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   14 21825 51950 52613 53167]\n",
      "['Absolute Value' 'Addition Whole Numbers'\n",
      " 'Addition and Subtraction Fractions' 'Addition and Subtraction Integers'\n",
      " 'Addition and Subtraction Positive Decimals']\n",
      "[array([18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 45, 70, 70, 45, 70,\n",
      "       45, 45]), array([90, 90, 90, 90, 90, 90, 90, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48]), array([30, 30, 30, 30, 29, 29]), array([ 4, 33, 51, 25, 25, 25]), array([ 4,  4,  4,  4,  3,  3, 48, 48, 21, 77, 48, 47,  3,  2,  2,  2,  2,\n",
      "        2,  1,  1,  1,  2,  4, 48,  2,  2,  4, 55, 56, 48, 52, 52, 52, 84,\n",
      "       89, 89, 89, 89, 50, 16, 90, 90, 66, 66, 90, 90, 90, 90, 90, 90, 22,\n",
      "       87,  1,  1, 87, 56, 54, 67, 55, 30, 30, 30, 30, 30, 30, 30, 30, 24,\n",
      "       20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19, 90, 90, 90, 16,  9,  9,\n",
      "        9,  9,  9,  1,  1,  3,  3,  3,  3,  4,  2,  2,  1,  1,  1,  1,  1,\n",
      "       56, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 92, 92, 92, 92, 92, 92,\n",
      "       60, 60, 60, 60, 60, 49, 49, 49, 49, 27, 27, 27, 27, 48, 48, 48, 48,\n",
      "       48, 33, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 48, 48,  3, 43, 43,\n",
      "       43, 43, 43, 43, 43, 43, 56, 56, 56, 54, 54, 54, 54, 54, 54, 55, 55,\n",
      "       55, 55, 55, 55, 55, 55, 55, 53, 52, 52, 52, 52, 52, 52, 53, 53, 53,\n",
      "       53, 53, 60, 64, 77,  3, 21, 33, 50, 85, 85, 85, 85, 85, 85, 67, 67,\n",
      "       67, 67, 67, 67, 34, 26, 32, 32, 32, 80, 80, 80, 80, 80, 68, 46, 53,\n",
      "       53, 53, 53, 90, 90, 90, 90, 90, 45, 44, 30, 30, 30, 30, 30, 30, 30,\n",
      "       30, 30, 30, 30, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 79,\n",
      "       79, 79, 79, 79, 58, 16, 16, 16, 16, 16, 16, 16, 67])]\n",
      "[array([0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0]), array([0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array([0, 1, 1, 1, 1, 1]), array([0, 1, 0, 1, 1, 1]), array([0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "       1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1])]\n",
      "5185\n",
      "577\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./datasets/ASSIST2009\"\n",
    "pkl_files = [f for f in os.listdir(data_dir) if f.endswith(\".pkl\")]\n",
    "\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "\n",
    "for file in pkl_files:\n",
    "\n",
    "    with open(os.path.join(data_dir, file), \"rb\") as f:\n",
    "        data_dict[os.path.splitext(file)[0]] = pickle.load(f)\n",
    "\n",
    "\n",
    "print(data_dict[\"u_list\"][:5])\n",
    "print(data_dict[\"q_list\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c796a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dict[\"q_seqs\"][:5])\n",
    "print(data_dict[\"r_seqs\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e5ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_dict[\"train_indices\"]))\n",
    "print(len(data_dict[\"test_indices\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9095f",
   "metadata": {
    "id": "e9b9095f"
   },
   "source": [
    "*q_seqs*, *r_seqs* are finally converted in datasets which consists of pairs *(q, r)*, where *q* and *r* are 1-d arrays. *q* is a sequence of KC indices and *r* a sequence of responses (0 or 1). The sequences have length *seq_len* and are padded at the end with -1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23898c33",
   "metadata": {
    "id": "23898c33"
   },
   "source": [
    "# Configuration\n",
    "\n",
    "The configuration file config.json allows to specify parameters for the training and for the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e507e102",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739189249530,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "e507e102",
    "outputId": "8163df1c-cb86-469e-fb88-8b38a9e3f744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"train_config\": {\n",
      "        \"batch_size\": 256,\n",
      "        \"num_epochs\": 100,\n",
      "        \"train_ratio\": 0.9,\n",
      "        \"learning_rate\": 0.001,\n",
      "        \"optimizer\": \"adam\",\n",
      "        \"seq_len\": 100\n",
      "    },\n",
      "    \"dkt\": {\n",
      "        \"emb_size\": 30,\n",
      "        \"hidden_size\": 30\n",
      "    },\n",
      "    \"dkvmn\": {\n",
      "        \"dim_s\": 50,\n",
      "        \"size_m\": 20\n",
      "    },\n",
      "    \"sakt\": {\n",
      "        \"n\": 100,\n",
      "        \"d\": 100,\n",
      "        \"num_attn_heads\": 5,\n",
      "        \"dropout\": 0.2\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6038d1",
   "metadata": {
    "id": "da6038d1"
   },
   "source": [
    "# Fitting the model\n",
    "\n",
    "Now you can fit a model. Here are there are three possibilities: Deep Knowledge Tracing (**dkt**, https://arxiv.org/abs/1506.05908), Dynamic Key-Value Memory Networks (**dkvmn**, https://arxiv.org/abs/1611.08108), and Self-Attentive Knowledge Tracing (**sakt**, https://arxiv.org/abs/1907.06837). After running it, results (loss and aucs) for the test set can be found in the folder *ckpts*. You can see the code for these models in the folder **./models**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7c49e2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7c49e2f",
    "outputId": "d16752c5-3ffa-45bd-8619-60eddc014c0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1,   AUC: 0.6087442574561587,   Loss Mean: 0.6810033321380615\n",
      "Epoch: 2,   AUC: 0.6577646554591885,   Loss Mean: 0.6603951454162598\n",
      "Epoch: 3,   AUC: 0.6793648271025068,   Loss Mean: 0.6481128334999084\n",
      "Epoch: 4,   AUC: 0.692401768759416,   Loss Mean: 0.6413626670837402\n",
      "Epoch: 5,   AUC: 0.7020341044668175,   Loss Mean: 0.636570155620575\n",
      "Epoch: 6,   AUC: 0.7081789138963219,   Loss Mean: 0.6345170140266418\n",
      "Epoch: 7,   AUC: 0.7128565880959479,   Loss Mean: 0.6330138444900513\n",
      "Epoch: 8,   AUC: 0.7168529098267766,   Loss Mean: 0.6294288635253906\n",
      "Epoch: 9,   AUC: 0.7198871756225849,   Loss Mean: 0.6285971999168396\n",
      "Epoch: 10,   AUC: 0.7227566633328069,   Loss Mean: 0.6259570121765137\n",
      "Epoch: 11,   AUC: 0.7244276957465241,   Loss Mean: 0.6258088946342468\n",
      "Epoch: 12,   AUC: 0.7260985292832802,   Loss Mean: 0.6256386041641235\n",
      "Epoch: 13,   AUC: 0.7271186374032516,   Loss Mean: 0.624829113483429\n",
      "Epoch: 14,   AUC: 0.727731311975175,   Loss Mean: 0.6229256987571716\n",
      "Epoch: 15,   AUC: 0.7290428657583694,   Loss Mean: 0.6219868659973145\n",
      "Epoch: 16,   AUC: 0.7309476553110876,   Loss Mean: 0.6220192909240723\n",
      "Epoch: 17,   AUC: 0.7310416275163163,   Loss Mean: 0.6214064955711365\n",
      "Epoch: 18,   AUC: 0.7326301487199642,   Loss Mean: 0.6212317943572998\n",
      "Epoch: 19,   AUC: 0.731852866528421,   Loss Mean: 0.6212485432624817\n",
      "Epoch: 20,   AUC: 0.733749391322855,   Loss Mean: 0.6194396018981934\n",
      "Epoch: 21,   AUC: 0.7344118050227547,   Loss Mean: 0.6193664073944092\n",
      "Epoch: 22,   AUC: 0.7355312976423967,   Loss Mean: 0.6189874410629272\n",
      "Epoch: 23,   AUC: 0.7354420729143398,   Loss Mean: 0.619128406047821\n",
      "Epoch: 24,   AUC: 0.7363052926818824,   Loss Mean: 0.6178659796714783\n",
      "Epoch: 25,   AUC: 0.736381459716892,   Loss Mean: 0.6184922456741333\n",
      "Epoch: 26,   AUC: 0.7375236470388971,   Loss Mean: 0.6183716058731079\n",
      "Epoch: 27,   AUC: 0.7375556150898473,   Loss Mean: 0.6168915629386902\n",
      "Epoch: 28,   AUC: 0.7378668632161991,   Loss Mean: 0.6169344782829285\n",
      "Epoch: 29,   AUC: 0.7381970614758462,   Loss Mean: 0.617019534111023\n",
      "Epoch: 30,   AUC: 0.738086713173419,   Loss Mean: 0.6176114082336426\n",
      "Epoch: 31,   AUC: 0.7389104757518754,   Loss Mean: 0.6177119016647339\n",
      "Epoch: 32,   AUC: 0.7394927846529354,   Loss Mean: 0.6155709028244019\n",
      "Epoch: 33,   AUC: 0.739227877699624,   Loss Mean: 0.6163873672485352\n",
      "Epoch: 34,   AUC: 0.7401356174954631,   Loss Mean: 0.6151619553565979\n",
      "Epoch: 35,   AUC: 0.7391444999542243,   Loss Mean: 0.6159578561782837\n",
      "Epoch: 36,   AUC: 0.7397801249274611,   Loss Mean: 0.61583411693573\n",
      "Epoch: 37,   AUC: 0.7406383841353734,   Loss Mean: 0.6147986054420471\n",
      "Epoch: 38,   AUC: 0.7404413624121907,   Loss Mean: 0.6149459481239319\n",
      "Epoch: 39,   AUC: 0.7403759773495734,   Loss Mean: 0.6154811978340149\n",
      "Epoch: 40,   AUC: 0.7401582440114397,   Loss Mean: 0.6155183911323547\n",
      "Epoch: 41,   AUC: 0.7408217572168243,   Loss Mean: 0.6139262318611145\n",
      "Epoch: 42,   AUC: 0.7407058574060825,   Loss Mean: 0.6140692830085754\n",
      "Epoch: 43,   AUC: 0.7410528238346514,   Loss Mean: 0.615258514881134\n",
      "Epoch: 44,   AUC: 0.7415718927031747,   Loss Mean: 0.6148185729980469\n",
      "Epoch: 45,   AUC: 0.7406130472105268,   Loss Mean: 0.6154323816299438\n",
      "Epoch: 46,   AUC: 0.7405188079419504,   Loss Mean: 0.6146109700202942\n",
      "Epoch: 47,   AUC: 0.739808135326885,   Loss Mean: 0.6137439012527466\n",
      "Epoch: 48,   AUC: 0.7411235700519208,   Loss Mean: 0.6138606667518616\n",
      "Epoch: 49,   AUC: 0.7408555691413143,   Loss Mean: 0.6139848232269287\n",
      "Epoch: 50,   AUC: 0.7421193839305416,   Loss Mean: 0.6131072044372559\n",
      "Epoch: 51,   AUC: 0.7414586635259108,   Loss Mean: 0.6141816973686218\n",
      "Epoch: 52,   AUC: 0.7415390950511866,   Loss Mean: 0.6135061979293823\n",
      "Epoch: 53,   AUC: 0.7418076016774942,   Loss Mean: 0.6126844882965088\n",
      "Epoch: 54,   AUC: 0.7422990067607257,   Loss Mean: 0.6139667630195618\n",
      "Epoch: 55,   AUC: 0.7414884496124876,   Loss Mean: 0.612089216709137\n",
      "Epoch: 56,   AUC: 0.7417367617039432,   Loss Mean: 0.6129229664802551\n",
      "Epoch: 57,   AUC: 0.7420025891734747,   Loss Mean: 0.612464964389801\n",
      "Epoch: 58,   AUC: 0.7414009267029982,   Loss Mean: 0.6125786900520325\n",
      "Epoch: 59,   AUC: 0.7411987427021247,   Loss Mean: 0.6126870512962341\n",
      "Epoch: 60,   AUC: 0.7422575181855366,   Loss Mean: 0.6124138832092285\n",
      "Epoch: 61,   AUC: 0.7428234197373043,   Loss Mean: 0.6120958924293518\n",
      "Epoch: 62,   AUC: 0.7430547193252857,   Loss Mean: 0.6113222241401672\n",
      "Epoch: 63,   AUC: 0.7424821070966301,   Loss Mean: 0.6117130517959595\n",
      "Epoch: 64,   AUC: 0.742233147234501,   Loss Mean: 0.6112752556800842\n",
      "Epoch: 65,   AUC: 0.7422076853012789,   Loss Mean: 0.6119102239608765\n",
      "Epoch: 66,   AUC: 0.7423002255923874,   Loss Mean: 0.6110848188400269\n",
      "Epoch: 67,   AUC: 0.7419857073605749,   Loss Mean: 0.6119123697280884\n",
      "Epoch: 68,   AUC: 0.7420662866230219,   Loss Mean: 0.610762894153595\n",
      "Epoch: 69,   AUC: 0.7411634676114209,   Loss Mean: 0.6115638017654419\n",
      "Epoch: 70,   AUC: 0.7421916075195221,   Loss Mean: 0.6094694137573242\n",
      "Epoch: 71,   AUC: 0.7417575926450708,   Loss Mean: 0.6111318469047546\n",
      "Epoch: 72,   AUC: 0.7416211062277536,   Loss Mean: 0.6115210652351379\n",
      "Epoch: 73,   AUC: 0.7421492552501017,   Loss Mean: 0.6099762916564941\n",
      "Epoch: 74,   AUC: 0.742456576977021,   Loss Mean: 0.6103585362434387\n",
      "Epoch: 75,   AUC: 0.7422177996153014,   Loss Mean: 0.6092710494995117\n",
      "Epoch: 76,   AUC: 0.7412445355429722,   Loss Mean: 0.6098280549049377\n",
      "Epoch: 77,   AUC: 0.7414514158812278,   Loss Mean: 0.6099178194999695\n",
      "Epoch: 78,   AUC: 0.7414699739427997,   Loss Mean: 0.6091938018798828\n",
      "Epoch: 79,   AUC: 0.741666163223845,   Loss Mean: 0.6096874475479126\n",
      "Epoch: 80,   AUC: 0.7413980657158575,   Loss Mean: 0.6094614863395691\n",
      "Epoch: 81,   AUC: 0.7412930160638944,   Loss Mean: 0.6088323593139648\n",
      "Epoch: 82,   AUC: 0.7413280354556482,   Loss Mean: 0.6099457740783691\n",
      "Epoch: 83,   AUC: 0.7403881088442017,   Loss Mean: 0.6086252331733704\n",
      "Epoch: 84,   AUC: 0.7409309435095788,   Loss Mean: 0.6103068590164185\n",
      "Epoch: 85,   AUC: 0.7408636776391291,   Loss Mean: 0.6085677146911621\n",
      "Epoch: 86,   AUC: 0.7399824737121024,   Loss Mean: 0.6084284782409668\n",
      "Epoch: 87,   AUC: 0.7397009861024326,   Loss Mean: 0.6102069616317749\n",
      "Epoch: 88,   AUC: 0.7408289139463253,   Loss Mean: 0.6089800596237183\n",
      "Epoch: 89,   AUC: 0.7404318788222446,   Loss Mean: 0.6085713505744934\n",
      "Epoch: 90,   AUC: 0.740864635089642,   Loss Mean: 0.6095835566520691\n",
      "Epoch: 91,   AUC: 0.7407836921664661,   Loss Mean: 0.6079288721084595\n",
      "Epoch: 92,   AUC: 0.7402792237079885,   Loss Mean: 0.6092697978019714\n",
      "Epoch: 93,   AUC: 0.7404226310435527,   Loss Mean: 0.6091522574424744\n",
      "Epoch: 94,   AUC: 0.7403955411603487,   Loss Mean: 0.608633279800415\n",
      "Epoch: 95,   AUC: 0.7404597897831883,   Loss Mean: 0.608134388923645\n",
      "Epoch: 96,   AUC: 0.7402179497162673,   Loss Mean: 0.6082423329353333\n",
      "Epoch: 97,   AUC: 0.7404438938317959,   Loss Mean: 0.608929455280304\n",
      "Epoch: 98,   AUC: 0.7400884921789761,   Loss Mean: 0.6083080172538757\n",
      "Epoch: 99,   AUC: 0.7390598181441792,   Loss Mean: 0.6088262796401978\n",
      "Epoch: 100,   AUC: 0.7395053337891822,   Loss Mean: 0.6069015860557556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benja\\anaconda3\\envs\\AMLDAIEd\\Lib\\site-packages\\torch\\__init__.py:1236: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:436.)\n",
      "  _C._set_default_tensor_type(t)\n",
      "g:\\My Drive\\Supervision\\AMLD-workshop\\AMLD2024-Education-Workshop\\DeepModels\\models\\utils.py:91: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:80.)\n",
      "  q_seqs.append(FloatTensor(q_seq[:-1]))\n"
     ]
    }
   ],
   "source": [
    "# model_name can be dkt, dkvmn or sakt\n",
    "!python train.py --model_name=dkt --dataset_name=ASSIST2009"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa364c",
   "metadata": {
    "id": "a0aa364c"
   },
   "source": [
    "Since this takes a while to run, you have the precomputed results for three models (dkt, dkvmn, sakt) in the folder *ckpts_precomputed/[model_name]/[dataset_name]*. Mind that you would need to tune the hyperparameters of the models and implement early stopping using a validation dataset for each of the models if you wanted to compare them, but this would require multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72a67f",
   "metadata": {
    "id": "ce72a67f"
   },
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "combined_df = None\n",
    "for model_name in [\"dkt\", \"dkvmn\", \"sakt\"]:\n",
    "    ckpt_dir = f\"ckpts_precomputed/{model_name}/ASSIST2009\"\n",
    "\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        continue\n",
    "\n",
    "    pkl_files = [f for f in os.listdir(ckpt_dir) if f.endswith(\".pkl\")]\n",
    "\n",
    "    if len(pkl_files) == 0:\n",
    "        continue\n",
    "\n",
    "    results_dict[model_name] = {}\n",
    "\n",
    "    for file in pkl_files:\n",
    "        with open(os.path.join(ckpt_dir, file), \"rb\") as f:\n",
    "            results_dict[model_name][os.path.splitext(file)[0]] = pickle.load(f)\n",
    "\n",
    "    # Create DataFrames for plotting\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Epoch\": range(len(results_dict[model_name][\"aucs\"])),\n",
    "            \"AUC\": results_dict[model_name][\"aucs\"],\n",
    "            \"Loss\": results_dict[model_name][\"loss_means\"],\n",
    "            \"Model\": model_name,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if combined_df is None:\n",
    "        combined_df = df\n",
    "    else:\n",
    "        combined_df = pd.concat([combined_df, df])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Plot Loss\n",
    "sns.lineplot(ax=axes[0], data=combined_df, x=\"Epoch\", y=\"Loss\", hue=\"Model\")\n",
    "axes[0].set_title(\"Loss\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot AUC\n",
    "sns.lineplot(ax=axes[1], data=combined_df, x=\"Epoch\", y=\"AUC\", hue=\"Model\")\n",
    "axes[1].set_title(\"AUC\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"AUC\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AMLDAIEd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
