{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d34927",
   "metadata": {
    "id": "b8d34927"
   },
   "source": [
    "## Deep Knowledge Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c87c5e",
   "metadata": {
    "id": "c4c87c5e"
   },
   "source": [
    "We will try out three different deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d5f31a",
   "metadata": {
    "executionInfo": {
     "elapsed": 1979,
     "status": "ok",
     "timestamp": 1739188664514,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "c9d5f31a"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import gdown\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4303fab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1418,
     "status": "ok",
     "timestamp": 1739188665935,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "d4303fab",
    "outputId": "577e6a93-f040-44ed-99a7-82dc931ec5d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'AMLD2025-Education-Workshop'...\n",
      "remote: Enumerating objects: 144, done.\u001b[K\n",
      "remote: Counting objects: 100% (144/144), done.\u001b[K\n",
      "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
      "remote: Total 144 (delta 57), reused 113 (delta 29), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (144/144), 1.67 MiB | 5.27 MiB/s, done.\n",
      "Resolving deltas: 100% (57/57), done.\n",
      "/content/AMLD2025-Education-Workshop\n"
     ]
    }
   ],
   "source": [
    "# If running on colab, clone the repo\n",
    "!git clone https://github.com/benjamingarzon/AMLD2025-Education-Workshop.git\n",
    "%cd AMLD2025-Education-Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a507e09b",
   "metadata": {
    "id": "a507e09b"
   },
   "source": [
    "# Data\n",
    "\n",
    "We will fit data from the Assistments platform (https://www.commonsense.org/education/website/assistments). These data are from the course 2009.\n",
    "\n",
    "First make sure to download the data from https://drive.google.com/uc?id=1y_1QJ1piwRlM9WXjyR2_4Yk19NubVpjM and save it in the folder **./DeepModels/datasets/ASSIST2009/**. The data preparation script assumes that the data are in a file **./DeepModels/datasets/ASSIST2009/skill_builder_data.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2163acd0",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1739188667452,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "2163acd0"
   },
   "outputs": [],
   "source": [
    "url = \"https://drive.google.com/uc?id=1y_1QJ1piwRlM9WXjyR2_4Yk19NubVpjM\"\n",
    "output = \"skill_builder_data.zip\"\n",
    "gdown.download(url, output, quiet=False)\n",
    "!unzip skill_builder_data.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f7a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"DeepModels/datasets/ASSIST2009\", exist_ok=True)\n",
    "!mv skill_builder_data.csv DeepModels/datasets/ASSIST2009/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3441bede",
   "metadata": {
    "id": "3441bede"
   },
   "source": [
    "Inspect the data:\n",
    "- *user_id* - Student ID.\n",
    "- *log_id* - Indicates the order in which it was presented.\n",
    "- *sequence_id* - Knowledge Component (KC). Groups items (exercises/questions) of a similar topic or skill.\n",
    "- *correct* - Whether the response is correct (1) or incorrect (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94240d13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1739189228696,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "94240d13",
    "outputId": "2749fe07-52be-45f9-fb9a-74caa4498378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  order_id  assignment_id  user_id  assistment_id  problem_id  \\\n",
      "0           1  33022537         277618    64525          33139       51424   \n",
      "1           2  33022709         277618    64525          33150       51435   \n",
      "2           3  35450204         220674    70363          33159       51444   \n",
      "3           4  35450295         220674    70363          33110       51395   \n",
      "4           5  35450311         220674    70363          33196       51481   \n",
      "5           6  35450555         220674    70363          33172       51457   \n",
      "6           7  35450573         220674    70363          33174       51459   \n",
      "7           8  35480603         220674    70363          33123       51408   \n",
      "8           9  33140811         220674    70677          33168       51453   \n",
      "9          10  33140919         220674    70677          33112       51397   \n",
      "\n",
      "   original  correct  attempt_count  ms_first_response  ... hint_count  \\\n",
      "0         1        1              1              32454  ...          0   \n",
      "1         1        1              1               4922  ...          0   \n",
      "2         1        0              2              25390  ...          0   \n",
      "3         1        1              1               4859  ...          0   \n",
      "4         1        0             14              19813  ...          3   \n",
      "5         1        1              1              16031  ...          0   \n",
      "6         1        1              1              15047  ...          0   \n",
      "7         1        1              1              10732  ...          0   \n",
      "8         1        1              1              23241  ...          0   \n",
      "9         1        1              1              11512  ...          0   \n",
      "\n",
      "  hint_total  overlap_time  template_id  answer_id answer_text  first_action  \\\n",
      "0          3         32454        30799        NaN          26             0   \n",
      "1          3          4922        30799        NaN          55             0   \n",
      "2          3         42000        30799        NaN          88             0   \n",
      "3          3          4859        30059        NaN          41             0   \n",
      "4          4        124564        30060        NaN          65             0   \n",
      "5          4         16031        30060        NaN          12             0   \n",
      "6          4         15047        30060        NaN           6             0   \n",
      "7          3         10732        30059        NaN          55             0   \n",
      "8          4         23241        30060        NaN          12             0   \n",
      "9          2         11512        30059        NaN          36             0   \n",
      "\n",
      "  bottom_hint  opportunity  opportunity_original  \n",
      "0         NaN            1                   1.0  \n",
      "1         NaN            2                   2.0  \n",
      "2         NaN            1                   1.0  \n",
      "3         NaN            2                   2.0  \n",
      "4         0.0            3                   3.0  \n",
      "5         NaN            4                   4.0  \n",
      "6         NaN            5                   5.0  \n",
      "7         NaN            6                   6.0  \n",
      "8         NaN            1                   1.0  \n",
      "9         NaN            2                   2.0  \n",
      "\n",
      "[10 rows x 30 columns]\n",
      "4151\n",
      "(274590, 30)\n",
      "correct\n",
      "1    181695\n",
      "0     92895\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"DeepModels/datasets/ASSIST2009\"\n",
    "data = pd.read_csv(\n",
    "    os.path.join(data_dir, \"skill_builder_data.csv\"),\n",
    "    sep=\",\"\n",
    ")\n",
    "\n",
    "print(data.head(10))\n",
    "print(data.user_id.nunique())\n",
    "print(data.shape)\n",
    "print(data.correct.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa7030",
   "metadata": {
    "id": "27aa7030"
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "Since datasets can differ in how they are formatted. In the **data_loaders** folder there are preprocessing scripts. These are called when you run the model (no need to call them separately). We can run *train.py* with the option *--only_preprocess* to run only the preprocessing, to avoid a long wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d098e90d",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1739189232391,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "d098e90d"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"DeepModels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c129767",
   "metadata": {
    "executionInfo": {
     "elapsed": 16282,
     "status": "ok",
     "timestamp": 1739189249465,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "6c129767"
   },
   "outputs": [],
   "source": [
    "!python train.py --model_name=dkt --dataset_name=ASSIST2009 --only_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaff23eb",
   "metadata": {
    "id": "eaff23eb"
   },
   "source": [
    "Briefly, the preprocessing implements the following steps (see train.py and data_loaders/assist2009.py):\n",
    "\n",
    "- Sort responses by log_id (time) for each student.\n",
    "- Remove observations if correct is different from 1 or 0.\n",
    "- Reindex students and items (consecutive indices starting from 0).\n",
    "- Split sequences of KCs and responses so that they have uniform length (*seq_len*).\n",
    "- Split dataset in train and test (e.g., 90%/10%).\n",
    "\n",
    "The preprocessing creates the following files that are used to train the model:\n",
    "\n",
    "*u_list.pkl*: List of student ids.\n",
    "*u2idx.pkl*: Dict with mapping of student ids to indices.\n",
    "\n",
    "*q_list.pkl*: List of knowledge component (KC) ids.\n",
    "*q2idx.pkl*: Dict with mapping of KC ids to indices.\n",
    "\n",
    "*r_seqs.pkl*: List of sequences of responses. Each element is an array that corresponds to the sequence of responses of one student, ordered by timestamp (log_id).\n",
    "*q_seqs.pkl*: List of sequences of KCs. Each element is an array that corresponds to the sequence of KCs of one student, ordered by timestamp (log_id). It matches r_seqs.\n",
    "\n",
    "*train_indices.pkl*, *test_indices.pkl*: training/test indices\n",
    "\n",
    "Inspect these files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5313dc76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1739189249508,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "5313dc76",
    "outputId": "85aa5cf7-2e07-4d40-9462-e9644363867c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   14 21825 52613 53167 64525]\n",
      "['Addition Whole Numbers' 'Angles on Parallel Lines Cut by a Transversal'\n",
      " 'Area Circle' 'Box and Whisker' 'Calculations with Similar Figures']\n",
      "[array([ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5, 18, 28, 28, 18, 28,\n",
      "       18, 18]), array([33, 33, 33, 33, 33, 33, 33]), array([20]), array([ 8, 30,  0,  0,  0, 22, 23, 19,  4, 33, 33, 26, 26, 33, 33, 33, 33,\n",
      "       33, 33,  9,  0,  0, 23, 21, 22,  7,  7,  7,  7,  7,  6,  6,  6,  6,\n",
      "        6,  6, 33, 33, 33,  4,  2,  2,  2,  2,  2,  0,  0,  0,  0,  0,  0,\n",
      "        0, 23,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 34, 34, 34, 34, 34,\n",
      "       34, 11, 11, 11, 11, 23, 23, 23, 21, 21, 21, 21, 21, 21, 22, 22, 22,\n",
      "       22, 22, 22, 22, 22, 22, 30,  8, 19, 27, 33, 33, 33, 33, 33, 18, 17,\n",
      "       31, 31, 31, 31, 31,  4,  4,  4,  4,  4,  4,  4]), array([ 0, 30,  8, 22, 23,  0,  0,  0,  0,  0,  0,  0, 23,  9,  9,  9,  9,\n",
      "        9,  9,  9,  9, 34, 11, 23, 23, 23, 21, 21, 21, 21, 21, 21, 22, 22,\n",
      "       22, 22, 22, 22, 22, 22, 22, 30,  5,  5, 22, 22, 22, 22, 22, 22, 22,\n",
      "       22,  0,  0,  0,  0,  0,  0,  0, 23,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "        9, 34, 11, 23, 23, 23, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22,\n",
      "       22, 22, 22, 22, 30, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,  5,\n",
      "        8,  8, 19, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
      "       27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
      "        7,  4,  4,  4,  4,  4,  4, 15, 15, 27, 27, 22,  3,  3,  5,  5,  5,\n",
      "        5,  5,  5,  5,  5,  5,  5, 25, 25, 25, 25, 25, 25, 10, 14, 14, 14,\n",
      "       33, 33, 28, 18, 33, 33, 33, 33, 33, 10, 10, 10, 10, 10, 10, 10, 26,\n",
      "       10, 26, 26, 26, 26, 33, 33, 33, 33, 31, 31, 32, 32, 32, 35, 35, 35,\n",
      "       35, 35, 35, 35, 35, 35, 35, 35, 35, 20, 20, 20, 10, 34, 34, 34, 34,\n",
      "       12, 12, 12, 12, 12,  4, 24,  6,  6,  6,  4,  4,  4,  4,  4,  2,  4,\n",
      "        2,  4, 12])]\n",
      "[array([0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0]), array([0, 1, 1, 1, 0, 1, 0]), array([0]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "       1, 1, 1, 1]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "       0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1])]\n",
      "3208\n",
      "357\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./datasets/ASSIST2009\"\n",
    "pkl_files = [f for f in os.listdir(data_dir) if f.endswith(\".pkl\")]\n",
    "\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "\n",
    "for file in pkl_files:\n",
    "\n",
    "    with open(os.path.join(data_dir, file), \"rb\") as f:\n",
    "        data_dict[os.path.splitext(file)[0]] = pickle.load(f)\n",
    "\n",
    "\n",
    "print(data_dict[\"u_list\"][:5])\n",
    "print(data_dict[\"q_list\"][:5])\n",
    "\n",
    "\n",
    "print(data_dict[\"q_seqs\"][:5])\n",
    "\n",
    "\n",
    "print(data_dict[\"r_seqs\"][:5])\n",
    "\n",
    "print(len(data_dict[\"train_indices\"]))\n",
    "print(len(data_dict[\"test_indices\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9095f",
   "metadata": {
    "id": "e9b9095f"
   },
   "source": [
    "*q_seqs*, *r_seqs* are finally converted in datasets which consists of pairs *(q, r)*, where *q* and *r* are 1-d arrays. *q* is a sequence of KC indices and *r* a sequence of responses (0 or 1). The sequences have length *seq_len* and are padded at the end with -1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23898c33",
   "metadata": {
    "id": "23898c33"
   },
   "source": [
    "# Configuration\n",
    "\n",
    "The configuration file config.json allows to specify parameters for the training and for the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e507e102",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739189249530,
     "user": {
      "displayName": "Benjamin Garzon",
      "userId": "05948891443763251616"
     },
     "user_tz": -60
    },
    "id": "e507e102",
    "outputId": "8163df1c-cb86-469e-fb88-8b38a9e3f744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"train_config\": {\n",
      "        \"batch_size\": 256,\n",
      "        \"num_epochs\": 200,\n",
      "        \"train_ratio\": 0.9,\n",
      "        \"learning_rate\": 0.001,\n",
      "        \"optimizer\": \"adam\",\n",
      "        \"seq_len\": 100\n",
      "    },\n",
      "    \"dkt\": {\n",
      "        \"emb_size\": 50,\n",
      "        \"hidden_size\": 50\n",
      "    },\n",
      "    \"dkvmn\": {\n",
      "        \"dim_s\": 50,\n",
      "        \"size_m\": 20\n",
      "    },\n",
      "    \"sakt\": {\n",
      "        \"n\": 100,\n",
      "        \"d\": 100,\n",
      "        \"num_attn_heads\": 5,\n",
      "        \"dropout\": 0.2\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6038d1",
   "metadata": {
    "id": "da6038d1"
   },
   "source": [
    "# Fitting the model\n",
    "\n",
    "Now you can fit a model. Here are there are three possibilities: Deep Knowledge Tracing (**dkt**, https://arxiv.org/abs/1506.05908), Dynamic Key-Value Memory Networks (**dkvmn**, https://arxiv.org/abs/1611.08108), and Self-Attentive Knowledge Tracing (**sakt**, https://arxiv.org/abs/1907.06837). After running it, results (loss and aucs) for the test set can be found in the folder *ckpts*. You can see the code for these models in the folder **./models**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c49e2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7c49e2f",
    "outputId": "d16752c5-3ffa-45bd-8619-60eddc014c0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1,   AUC: 0.6172876917652882,   Loss Mean: 0.6766604781150818\n",
      "Epoch: 2,   AUC: 0.6496446325024796,   Loss Mean: 0.6522507071495056\n",
      "Epoch: 3,   AUC: 0.66781883817627,   Loss Mean: 0.6416162848472595\n",
      "Epoch: 4,   AUC: 0.6816481995884448,   Loss Mean: 0.6361633539199829\n",
      "Epoch: 5,   AUC: 0.6897770595008041,   Loss Mean: 0.6319649815559387\n",
      "Epoch: 6,   AUC: 0.6965738204183785,   Loss Mean: 0.6292781829833984\n",
      "Epoch: 7,   AUC: 0.7017494141889699,   Loss Mean: 0.6272977590560913\n",
      "Epoch: 8,   AUC: 0.7049351374899437,   Loss Mean: 0.6282800436019897\n",
      "Epoch: 9,   AUC: 0.7061627771367227,   Loss Mean: 0.6237517595291138\n",
      "Epoch: 10,   AUC: 0.7081211772744564,   Loss Mean: 0.622798502445221\n",
      "Epoch: 11,   AUC: 0.71038235325766,   Loss Mean: 0.6240051984786987\n",
      "Epoch: 12,   AUC: 0.7117253709345316,   Loss Mean: 0.6226149797439575\n",
      "Epoch: 13,   AUC: 0.7137116216236746,   Loss Mean: 0.6218594312667847\n",
      "Epoch: 14,   AUC: 0.7137068941508146,   Loss Mean: 0.6206926703453064\n",
      "Epoch: 15,   AUC: 0.715080017324309,   Loss Mean: 0.6202088594436646\n",
      "Epoch: 16,   AUC: 0.7154068459187231,   Loss Mean: 0.6197310090065002\n",
      "Epoch: 17,   AUC: 0.7155750569195645,   Loss Mean: 0.6191917061805725\n",
      "Epoch: 18,   AUC: 0.7150351953431346,   Loss Mean: 0.61920166015625\n",
      "Epoch: 19,   AUC: 0.7158536217743207,   Loss Mean: 0.619267463684082\n",
      "Epoch: 20,   AUC: 0.7170866218610372,   Loss Mean: 0.617457389831543\n",
      "Epoch: 21,   AUC: 0.7191626549740768,   Loss Mean: 0.6179484724998474\n",
      "Epoch: 22,   AUC: 0.7197650813900718,   Loss Mean: 0.6173868775367737\n",
      "Epoch: 23,   AUC: 0.7184395296484944,   Loss Mean: 0.6173229217529297\n",
      "Epoch: 24,   AUC: 0.7200030967914266,   Loss Mean: 0.6155592203140259\n",
      "Epoch: 25,   AUC: 0.7220225189114737,   Loss Mean: 0.6154502034187317\n",
      "Epoch: 26,   AUC: 0.7191035121127745,   Loss Mean: 0.6145658493041992\n",
      "Epoch: 27,   AUC: 0.7202123913116408,   Loss Mean: 0.6152709126472473\n",
      "Epoch: 28,   AUC: 0.7214245232650215,   Loss Mean: 0.6141212582588196\n",
      "Epoch: 29,   AUC: 0.7207987364078232,   Loss Mean: 0.6138476133346558\n",
      "Epoch: 30,   AUC: 0.7216958287786077,   Loss Mean: 0.6131600737571716\n",
      "Epoch: 31,   AUC: 0.7211714748955762,   Loss Mean: 0.6148968935012817\n",
      "Epoch: 32,   AUC: 0.72119349028174,   Loss Mean: 0.6139873266220093\n",
      "Epoch: 33,   AUC: 0.721510824369992,   Loss Mean: 0.6123498678207397\n",
      "Epoch: 34,   AUC: 0.7224666442174343,   Loss Mean: 0.6126996278762817\n",
      "Epoch: 35,   AUC: 0.7214823606317264,   Loss Mean: 0.6127790808677673\n",
      "Epoch: 36,   AUC: 0.7217160639448661,   Loss Mean: 0.6117220520973206\n",
      "Epoch: 37,   AUC: 0.722958242054206,   Loss Mean: 0.6105331778526306\n",
      "Epoch: 38,   AUC: 0.7214711254661011,   Loss Mean: 0.6116700768470764\n",
      "Epoch: 39,   AUC: 0.72175750350822,   Loss Mean: 0.6120371222496033\n",
      "Epoch: 40,   AUC: 0.7210019979605801,   Loss Mean: 0.6092237234115601\n",
      "Epoch: 41,   AUC: 0.72250608597845,   Loss Mean: 0.6102283596992493\n",
      "Epoch: 42,   AUC: 0.7223352244279718,   Loss Mean: 0.6099472045898438\n",
      "Epoch: 43,   AUC: 0.720134615481995,   Loss Mean: 0.6101311445236206\n",
      "Epoch: 44,   AUC: 0.7225703519170357,   Loss Mean: 0.6082416772842407\n",
      "Epoch: 45,   AUC: 0.7220810090254776,   Loss Mean: 0.6089274883270264\n",
      "Epoch: 46,   AUC: 0.721909296925489,   Loss Mean: 0.6091945171356201\n",
      "Epoch: 47,   AUC: 0.7215281518437382,   Loss Mean: 0.6078506708145142\n",
      "Epoch: 48,   AUC: 0.7204463517676555,   Loss Mean: 0.610490083694458\n",
      "Epoch: 49,   AUC: 0.7207572375038058,   Loss Mean: 0.607434868812561\n",
      "Epoch: 50,   AUC: 0.7202091275751474,   Loss Mean: 0.609738290309906\n",
      "Epoch: 51,   AUC: 0.7208701034458095,   Loss Mean: 0.6061105132102966\n"
     ]
    }
   ],
   "source": [
    "# model_name can be dkt, dkvmn or sakt\n",
    "!python train.py --model_name=dkt --dataset_name=ASSIST2009"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa364c",
   "metadata": {
    "id": "a0aa364c"
   },
   "source": [
    "Since this takes a while to run, you have the precomputed results for three models (dkt, dkvmn, sakt) in the folder *ckpts_precomputed/[model_name]/[dataset_name]*. Mind that you would need to tune the hyperparameters of the models and implement early stopping using a validation dataset for each of the models if you wanted to compare them, but this would require multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72a67f",
   "metadata": {
    "id": "ce72a67f"
   },
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "combined_df = None\n",
    "for model_name in [\"dkt\", \"dkvmn\", \"sakt\"]:\n",
    "    ckpt_dir = f\"ckpts_precomputed/{model_name}/ASSIST2009\"\n",
    "\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        continue\n",
    "\n",
    "    pkl_files = [f for f in os.listdir(ckpt_dir) if f.endswith(\".pkl\")]\n",
    "\n",
    "    if len(pkl_files) == 0:\n",
    "        continue\n",
    "\n",
    "    results_dict[model_name] = {}\n",
    "\n",
    "    for file in pkl_files:\n",
    "        with open(os.path.join(ckpt_dir, file), \"rb\") as f:\n",
    "            results_dict[model_name][os.path.splitext(file)[0]] = pickle.load(f)\n",
    "\n",
    "    # Create DataFrames for plotting\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Epoch\": range(len(results_dict[model_name][\"aucs\"])),\n",
    "            \"AUC\": results_dict[model_name][\"aucs\"],\n",
    "            \"Loss\": results_dict[model_name][\"loss_means\"],\n",
    "            \"Model\": model_name,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if combined_df is None:\n",
    "        combined_df = df\n",
    "    else:\n",
    "        combined_df = pd.concat([combined_df, df])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Plot Loss\n",
    "sns.lineplot(ax=axes[0], data=combined_df, x=\"Epoch\", y=\"Loss\", hue=\"Model\")\n",
    "axes[0].set_title(\"Loss\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot AUC\n",
    "sns.lineplot(ax=axes[1], data=combined_df, x=\"Epoch\", y=\"AUC\", hue=\"Model\")\n",
    "axes[1].set_title(\"AUC\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"AUC\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AMLDAIEd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
